{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier, kernels\n",
    "from matplotlib import pyplot as pl\n",
    "from matplotlib import cm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will take the data on amplitude of the two frequencies (already\n",
    "generated by matlab) and classify the perceptual response during rivalry\n",
    "based on training data from the **test** set\n",
    "\n",
    "You can define who to include include in this analysis run in the next cell.\n",
    "You can also set some of the other parameters that might change from setup\n",
    "to setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "participants = ['stratus' + str(number) for number in [101]]\n",
    "\n",
    "# There are three possible perceptual reports\n",
    "perceptindices = {'lowfreq': -1, 'mixed': 0, 'highfreq': 1}\n",
    "# Use these colors for plots:\n",
    "colors = {'lowfreq': 'blue', 'mixed': 'gray', 'highfreq': 'red'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, this script requires a function that downsamples the data. This is due\n",
    "to the memory limitations that the machine learning algorithm has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleandata(data, downsamplefactor=20):\n",
    "    assert data.shape[1] == 3, \"Data not in the right format.\"\n",
    "\n",
    "    # trim the data of all timepoints where nothing was reported\n",
    "    # (this usually also removes the beginning and end of trials)\n",
    "    data = data[np.logical_not(np.isnan(data[:, 2])), :]\n",
    "\n",
    "    # downsample the data (to avoid memory issues!)\n",
    "    # average over timebins (n=downsamplefactor) with same percept\n",
    "    data = np.array([\n",
    "        np.mean(\n",
    "            data[(index - downsamplefactor / 2):\n",
    "                 (index + downsamplefactor / 2), :][\n",
    "                # logical index\n",
    "                np.equal(data[\n",
    "                    (index - downsamplefactor / 2):\n",
    "                    (index + downsamplefactor / 2), 2\n",
    "                ], data[index, 2]), :\n",
    "            ],\n",
    "            axis=0)\n",
    "        for index in np.arange(downsamplefactor / 2, data.shape[0],\n",
    "                               downsamplefactor)])\n",
    "    # split into x and y\n",
    "    x = data[:, 0:2]\n",
    "    y = data[:, 2]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section is where the model is actually trained. Set changes to\n",
    "the kernel below. You can also change whether the script produces a plot\n",
    "for each subject and what those plots look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainPredict(subjectid, makeplot=False):\n",
    "    print(\"testing participant \" + subjectid)\n",
    "    # Load training data from the file matlab generates\n",
    "    traindata = np.genfromtxt('csvdata/' + subjectid +\n",
    "                              '_sim.csv', delimiter=',',\n",
    "                              missing_values=['NaN', 'nan'],\n",
    "                              filling_values=None)\n",
    "    # Clean this data\n",
    "    trainx, trainy = cleandata(traindata)\n",
    "\n",
    "    # Train a Gaussian Process\n",
    "    anisokern = kernels.RBF()  # default kernel\n",
    "    gp = GaussianProcessClassifier(kernel=anisokern)  # Initialize the GPC\n",
    "    gp.fit(trainx, trainy)  # train this class on the data\n",
    "    trainx = trainy = None  # Discard all training data to preserve memory\n",
    "\n",
    "    # load test data\n",
    "    testdata = np.genfromtxt('csvdata/' + subjectid +\n",
    "                             '_rival.csv', delimiter=',',\n",
    "                             missing_values=['NaN', 'nan'],\n",
    "                             filling_values=None)\n",
    "    testx, testy = cleandata(testdata, downsamplefactor=2)  # clean data\n",
    "    testdata = None  # clear from memory\n",
    "    # now get a prediction for all points in the test data\n",
    "    predicty = gp.predict(testx)\n",
    "    proby = gp.predict_proba(testx)\n",
    "\n",
    "    if makeplot:\n",
    "        # make plot here\n",
    "        fig = pl.figure(1)\n",
    "        # make a kernel density plot\n",
    "        ax = pl.subplot2grid((2, 3), (0, 0), colspan=2, rowspan=2)\n",
    "        pl.xlim(0, 1)\n",
    "        xspan = np.linspace(0, 1, 200)\n",
    "        for percept, value in perceptindices.iteritems():\n",
    "            density = stats.gaussian_kde(proby[np.equal(testy, value), 1])\n",
    "            yspan = density(xspan)\n",
    "            yspan[0] = 0\n",
    "            yspan[-1] = 0\n",
    "            pl.plot(xspan, yspan, label=percept, color=colors[percept])\n",
    "            pl.fill(xspan, yspan, color=colors[percept], alpha=0.2)\n",
    "        pl.legend()\n",
    "\n",
    "        # make a plot of the kernel\n",
    "        lim = 3\n",
    "        res = 50\n",
    "        ax = pl.subplot2grid((2, 3), (0, 2))\n",
    "        # X axes:\n",
    "        x1, x2 = np.meshgrid(np.linspace(- lim, lim, res),\n",
    "                             np.linspace(- lim, lim, res))\n",
    "        xx = np.vstack([x1.reshape(x1.size), x2.reshape(x2.size)]).T\n",
    "        # Y:\n",
    "        y_pred = gp.predict_proba(xx)\n",
    "        y_pred = y_pred[:, 0].reshape((res, res))\n",
    "        ax.axes.set_aspect('equal')\n",
    "        pl.xticks([])\n",
    "        pl.yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        pl.xlabel('Frequency 1')\n",
    "        pl.ylabel('Frequency 2')\n",
    "        cax = pl.imshow(np.flipud(y_pred), cmap=cm.gray_r, alpha=0.8,\n",
    "                        extent=(- lim, lim, - lim, lim))\n",
    "        for color, value in (('b', 0.2), ('k', 0.5), ('r', 0.8)):\n",
    "            cs = pl.contour(x1, x2, y_pred, [value], colors=color,\n",
    "                            linestyles='dashed')\n",
    "            pl.clabel(cs, fontsize=11)\n",
    "\n",
    "        # Visualise the categorical predictions\n",
    "        ax = pl.subplot2grid((2, 3), (1, 2))\n",
    "        domindices = (np.equal(testy, index) for index in (-1, 1))\n",
    "        correctpercentage = [np.mean(np.equal(testy[domindex],\n",
    "                                              predicty[domindex]))\n",
    "                             for domindex in domindices]\n",
    "        pl.bar([-1.5, 0.5], correctpercentage)\n",
    "        pl.ylim(0, 1)\n",
    "        pl.xlim(-2, 2)\n",
    "        pl.ylabel('Correctly predicted')\n",
    "        pl.xticks([-1, 1])\n",
    "        ax.set_xticklabels(['Low Freq', 'High Freq'])\n",
    "\n",
    "        fig.subplots_adjust(wspace=0.5)\n",
    "        fig.suptitle(participant)\n",
    "        pl.savefig('graphs/' + participant + '.png')\n",
    "        # pl.show()\n",
    "\n",
    "    # Summarise prediction by reported percept\n",
    "    meanprediction = {'mean' + percept: np.mean(\n",
    "        proby[np.equal(testy, value), 1]\n",
    "    )\n",
    "        for percept, value in perceptindices.iteritems()}\n",
    "    predictiondev = {'stdev' + percept: np.std(\n",
    "        proby[np.equal(testy, perceptindices[percept])]\n",
    "    )\n",
    "        for percept in perceptindices}\n",
    "    predictionaccuracy = {'acc' + percept: np.mean(\n",
    "        np.equal(predicty[np.equal(testy, perceptindices[percept])],\n",
    "                 testy[np.equal(testy, perceptindices[percept])])\n",
    "    )\n",
    "        for percept in perceptindices}\n",
    "    return meanprediction, predictiondev, predictionaccuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is for calculating the proportions of each\n",
    "percept in a given rivalry trial for each subject. There is also a util\n",
    "function that is there to combine the various results into one\n",
    "dictionary for writing to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_proportions(subjectid):\n",
    "    testdata = np.genfromtxt('csvdata/' + subjectid +\n",
    "                             '_rival.csv', delimiter=',',\n",
    "                             missing_values=['NaN', 'nan'],\n",
    "                             filling_values=None)\n",
    "    testx, testy = cleandata(testdata)  # clean data\n",
    "    perceptprop = {'proportion' + percept: float(np.sum(\n",
    "        np.equal(testy, value)\n",
    "    )) / float(testy.size)\n",
    "        for percept, value in perceptindices.iteritems()}\n",
    "    return perceptprop\n",
    "\n",
    "\n",
    "def merge_dicts(*dict_args):\n",
    "    result = {}  # empty dict\n",
    "    for dictionary in dict_args:\n",
    "        # go through dict, update master dict\n",
    "        result.update(dictionary)\n",
    "    return result  # return master dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell opens a \"resultfile\" spreadsheet and creates a class\n",
    "for writing to that spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultfile = open('all-results.csv', 'w+')  # open file\n",
    "# open a \"writer\" which takes a dictionary as an argument:\n",
    "resultwriter = csv.DictWriter(resultfile, delimiter=',', lineterminator='\\n',\n",
    "                              fieldnames=['subject'] +\n",
    "                              ['mean' + percept\n",
    "                               for percept in perceptindices.keys()] +\n",
    "                              ['stdev' + percept\n",
    "                               for percept in perceptindices.keys()] +\n",
    "                              ['acc' + percept\n",
    "                               for percept in perceptindices.keys()] +\n",
    "                              ['proportion' + percept\n",
    "                               for percept in perceptindices.keys()])\n",
    "resultwriter.writeheader()  # write the column headers to the spreadsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the loop where the models get trained. Each subject's model is only\n",
    "in memory once, so if you want to create more plots / write more results to\n",
    "spreadsheet, make sure to change them before running this cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    for participant in participants:\n",
    "        # Train the model, predict percepts:\n",
    "        meanprediction, predictiondev, predictionaccuracy = trainPredict(\n",
    "            participant,\n",
    "            makeplot=True  # change to false if no \"summary\" plot is needed\n",
    "        )\n",
    "\n",
    "        # Work out the percept proportions during rivalry\n",
    "        proportions = compute_proportions(participant)\n",
    "\n",
    "        # Write to file:\n",
    "        meanprediction['subject'] = participant\n",
    "        all_results = merge_dicts(meanprediction, predictiondev,\n",
    "                                  predictionaccuracy, proportions)\n",
    "        resultwriter.writerow(all_results)\n",
    "finally:\n",
    "    resultfile.close()  # close file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
