{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier, kernels\n",
    "from matplotlib import pyplot as pl\n",
    "from matplotlib import cm\n",
    "import csv\n",
    "\n",
    "\n",
    "def merge_dicts(*dict_args):\n",
    "    result = {}  # empty dict\n",
    "    for dictionary in dict_args:\n",
    "        # go through dict, update master dict\n",
    "        result.update(dictionary)\n",
    "    return result  # return master dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "This code will take the data on amplitude of the two frequencies (already\n",
    "generated by matlab) and classify the perceptual response during rivalry\n",
    "based on training data from the **test** set\n",
    "\n",
    "You can define who to include include in this analysis run in the next cell.\n",
    "You can also set some of the other parameters that might change from setup\n",
    "to setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "participants = ['stratus' + str(number) for number in [101, 102, 103, 104, 105,\n",
    "                                                       106, 109, 112, 114, 116,\n",
    "                                                       117, 118, 119, 121, 122,\n",
    "                                                       123, 124, 125, 126, 127,\n",
    "                                                       128, 129, 130, 131, 132]]\n",
    "\n",
    "# There are three possible perceptual reports\n",
    "perceptindices = {'lowfreq': -1, 'mixed': 0, 'highfreq': 1}\n",
    "# Use these colors for plots:\n",
    "colors = {'lowfreq': 'blue', 'mixed': 'gray', 'highfreq': 'red'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "First we define a function that downsamples the data. This is done \"safely\"\n",
    "so we never average data over points where a different percept was reported.\n",
    "This is due to the memory limitations that the machine learning algorithm has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleandata(data, downsamplefactor=20):\n",
    "    assert data.shape[1] == 3, \"Data not in the right format.\"\n",
    "\n",
    "    # trim the data of all timepoints where nothing was reported\n",
    "    # (this usually also removes the beginning and end of trials)\n",
    "    data = data[np.logical_not(np.isnan(data[:, 2])), :]\n",
    "\n",
    "    # downsample the data (to avoid memory issues!)\n",
    "    # average over timebins (n=downsamplefactor) with same percept\n",
    "    data = np.array([\n",
    "        np.mean(\n",
    "            data[(index - downsamplefactor / 2):\n",
    "                 (index + downsamplefactor / 2), :][\n",
    "                # logical index\n",
    "                np.equal(data[\n",
    "                    (index - downsamplefactor / 2):\n",
    "                    (index + downsamplefactor / 2), 2\n",
    "                ], data[index, 2]), :\n",
    "            ],\n",
    "            axis=0)\n",
    "        for index in np.arange(downsamplefactor / 2, data.shape[0],\n",
    "                               downsamplefactor)])\n",
    "    # split into x and y\n",
    "    x = data[:, 0:2]\n",
    "    y = data[:, 2]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "The next section is where the model is actually trained. Set changes to\n",
    "the kernel below. You can also change whether the script produces a plot\n",
    "for each subject and what those plots look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainPredict(subjectid, makeplot=False):\n",
    "    print(\"testing participant \" + subjectid)\n",
    "    # Load training data from the file matlab generates\n",
    "    traindata = np.genfromtxt('csvdata/' + subjectid +\n",
    "                              '_sim.csv', delimiter=',',\n",
    "                              missing_values=['NaN', 'nan'],\n",
    "                              filling_values=None)\n",
    "    # Clean + downsample this data\n",
    "    trainx, trainy = cleandata(traindata, downsamplefactor=20)\n",
    "\n",
    "    # Train a Gaussian Process\n",
    "    anisokern = kernels.RBF()  # default kernel\n",
    "    gp = GaussianProcessClassifier(kernel=anisokern)  # Initialize the GPC\n",
    "    gp.fit(trainx, trainy)  # train this class on the data\n",
    "    trainx = trainy = None  # Discard all training data to preserve memory\n",
    "\n",
    "    # load test data\n",
    "    testdata = np.genfromtxt('csvdata/' + subjectid +\n",
    "                             '_rival.csv', delimiter=',',\n",
    "                             missing_values=['NaN', 'nan'],\n",
    "                             filling_values=None)\n",
    "\n",
    "    testx, testy = cleandata(testdata, downsamplefactor=4)  # clean data\n",
    "\n",
    "    testdata = None  # clear from memory\n",
    "    # work out percentage in percept for each data point:\n",
    "    percentages = assign_percentage(testy)\n",
    "\n",
    "    # get a prediction for all points in the test data:\n",
    "    predicty = gp.predict(testx)\n",
    "    proby = gp.predict_proba(testx)\n",
    "\n",
    "    if makeplot:\n",
    "        summaryplot(participant, testx, testy, predicty, proby, gp)\n",
    "\n",
    "    # Summarise prediction by reported percept\n",
    "    meanprediction = {'mean' + percept:\n",
    "                      proby[testy == value, 1].mean()\n",
    "                      for percept, value in perceptindices.iteritems()}\n",
    "    predictiondev = {'stdev' + percept:\n",
    "                     proby[testy == value, 1].std()\n",
    "                     for percept, value in perceptindices.iteritems()}\n",
    "    predictionaccuracy = {'acc' + percept:\n",
    "                          (predicty[testy == value] ==\n",
    "                           testy[testy == value]).mean()\n",
    "                          for percept, value in perceptindices.iteritems()}\n",
    "    # Summarise prediction by percentage in percept\n",
    "    predictioncourse = {percept:\n",
    "                        [proby[(testy == value) &\n",
    "                               (percentages < cutoff) &\n",
    "                               (percentages > cutoff - 0.1), 1].mean()\n",
    "                         for cutoff in np.linspace(0.1, 1, 10)]\n",
    "                        for percept, value in perceptinidices.iteritems()}\n",
    "\n",
    "    # Only return the summarised data\n",
    "    return meanprediction, predictiondev, predictionaccuracy, predictioncourse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to aid visualisation, we need to create a function that creates a\n",
    "plot summarising the results of our gaussian classifier for each participant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def summaryplot(participant, testx, testy, predicty, proby, gp):\n",
    "    # make plot here\n",
    "    fig = pl.figure(1)\n",
    "    # make a kernel density plot\n",
    "    ax = pl.subplot2grid((2, 3), (0, 0), colspan=2, rowspan=2)\n",
    "    pl.xlim(0, 1)\n",
    "    xspan = np.linspace(0, 1, 200)\n",
    "    for percept, value in perceptindices.iteritems():\n",
    "        density = stats.gaussian_kde(proby[np.equal(testy, value), 1])\n",
    "        yspan = density(xspan)\n",
    "        yspan[0] = 0\n",
    "        yspan[-1] = 0\n",
    "        pl.plot(xspan, yspan, label=percept, color=colors[percept])\n",
    "        pl.fill(xspan, yspan, color=colors[percept], alpha=0.2)\n",
    "    pl.legend()\n",
    "\n",
    "    # make a plot of the kernel\n",
    "    lim = 3\n",
    "    res = 50\n",
    "    ax = pl.subplot2grid((2, 3), (0, 2))\n",
    "    # X axes:\n",
    "    x1, x2 = np.meshgrid(np.linspace(- lim, lim, res),\n",
    "                         np.linspace(- lim, lim, res))\n",
    "    xx = np.vstack([x1.reshape(x1.size), x2.reshape(x2.size)]).T\n",
    "    # Y:\n",
    "    y_pred = gp.predict_proba(xx)\n",
    "    y_pred = y_pred[:, 0].reshape((res, res))\n",
    "    ax.axes.set_aspect('equal')\n",
    "    pl.xticks([])\n",
    "    pl.yticks([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    pl.xlabel('Frequency 1')\n",
    "    pl.ylabel('Frequency 2')\n",
    "    cax = pl.imshow(np.flipud(y_pred), cmap=cm.gray_r, alpha=0.8,\n",
    "                    extent=(- lim, lim, - lim, lim))\n",
    "    for color, value in (('b', 0.2), ('k', 0.5), ('r', 0.8)):\n",
    "        cs = pl.contour(x1, x2, y_pred, [value], colors=color,\n",
    "                        linestyles='dashed')\n",
    "        pl.clabel(cs, fontsize=11)\n",
    "\n",
    "    # Visualise the categorical predictions\n",
    "    ax = pl.subplot2grid((2, 3), (1, 2))\n",
    "    domindices = (np.equal(testy, index) for index in (-1, 1))\n",
    "    correctpercentage = [np.mean(np.equal(testy[domindex],\n",
    "                                          predicty[domindex]))\n",
    "                         for domindex in domindices]\n",
    "    pl.bar([-1.5, 0.5], correctpercentage)\n",
    "    pl.ylim(0, 1)\n",
    "    pl.xlim(-2, 2)\n",
    "    pl.ylabel('Correctly predicted')\n",
    "    pl.xticks([-1, 1])\n",
    "    ax.set_xticklabels(['Low Freq', 'High Freq'])\n",
    "\n",
    "    fig.subplots_adjust(wspace=0.5)\n",
    "    fig.suptitle(participant)\n",
    "    pl.savefig('graphs/' + participant + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavioral report parsing\n",
    "The following function is for calculating the proportions of each\n",
    "percept in a given rivalry trial for each subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_proportions(subjectid):\n",
    "    testdata = np.genfromtxt('csvdata/' + subjectid +\n",
    "                             '_rival.csv', delimiter=',',\n",
    "                             missing_values=['NaN', 'nan'],\n",
    "                             filling_values=None)\n",
    "    testx, testy = cleandata(testdata)  # clean data\n",
    "    perceptprop = {'proportion' + percept: float(np.sum(\n",
    "        np.equal(testy, value)\n",
    "    )) / float(testy.size)\n",
    "        for percept, value in perceptindices.iteritems()}\n",
    "    return perceptprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking predictions over the course of a rivalry period\n",
    "This function is for calculating the percentage of a particular rivalry\n",
    "period that a given data point is in. You can then use this to bin the\n",
    "probabilities by, and so trace the evolution of estimated probabilitie during\n",
    "the course of a perceptual period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def assign_percentage(y):\n",
    "    percentages = []\n",
    "    startpoint = 0\n",
    "    previous = 99\n",
    "    for timepoint in range(y.size):\n",
    "        percept = y[timepoint]\n",
    "        if percept != previous:\n",
    "            previous = percept\n",
    "            startpoint = timepoint\n",
    "            try:\n",
    "                endpoint = ((y != percept) &\n",
    "                            (np.arange(y.size) >= timepoint)).nonzero()[0][0]\n",
    "            except:\n",
    "                endpoint = y.size\n",
    "        percentages.append(float(timepoint - startpoint) /\n",
    "                           float(endpoint - startpoint))\n",
    "    return percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Saving\n",
    "The following cell opens a \"resultfile\" spreadsheet and creates a class\n",
    "for writing to that spreadsheet.\n",
    "\n",
    "trainPredict('stratus125', makeplot=False)\n",
    "raise KeyboardInterrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultfile = open('all-results.csv', 'w+')  # open file\n",
    "# open a \"writer\" which takes a dictionary as an argument:\n",
    "resultwriter = csv.DictWriter(resultfile, delimiter=',', lineterminator='\\n',\n",
    "                              fieldnames=['subject'] +\n",
    "                              ['mean' + percept\n",
    "                               for percept in perceptindices.keys()] +\n",
    "                              ['stdev' + percept\n",
    "                               for percept in perceptindices.keys()] +\n",
    "                              ['acc' + percept\n",
    "                               for percept in perceptindices.keys()] +\n",
    "                              ['proportion' + percept\n",
    "                               for percept in perceptindices.keys()])\n",
    "resultwriter.writeheader()  # write the column headers to the spreadsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the loop where the models get trained. Each subject's model is only\n",
    "in memory once, so if you want to create more plots / write more results to\n",
    "spreadsheet, make sure to change them before running this cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    for participant in participants:\n",
    "        # Train the model, predict percepts:\n",
    "        meanprediction, predictiondev, predictionaccuracy = trainPredict(\n",
    "            participant,\n",
    "            makeplot=True  # change to false if no \"summary\" plot is needed\n",
    "        )\n",
    "\n",
    "        # Work out the percept proportions during rivalry\n",
    "        proportions = compute_proportions(participant)\n",
    "\n",
    "        # Write to file:\n",
    "        meanprediction['subject'] = participant\n",
    "        all_results = merge_dicts(meanprediction, predictiondev,\n",
    "                                  predictionaccuracy, proportions)\n",
    "        resultwriter.writerow(all_results)\n",
    "finally:\n",
    "    resultfile.close()  # close file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
